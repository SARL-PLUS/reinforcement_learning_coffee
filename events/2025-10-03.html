<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>"Proximal Policy Optimization Algorithms" - A Deep Dive - RL Coffee</title>
    <link rel="stylesheet" href="../css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
    <style>
        .event-detail-container {
            max-width: 800px;
            margin: 40px auto;
            padding: 40px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .back-link {
            display: inline-block;
            margin-bottom: 20px;
            color: #00aaff;
            text-decoration: none;
            font-weight: bold;
        }
        .back-link:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="event-detail-container">
        <a href="/index.html" class="back-link">&larr; Back to Schedule</a>
        <h1>"Proximal Policy Optimization Algorithms" - A Deep Dive</h1>
        <p><strong>Date:</strong> October 3, 2025</p>
        <p><strong>Speaker:</strong> Dr. Eva Core</p>
        <hr>
        <h2>Abstract</h2>
        <p>
            This talk will provide a deep dive into Proximal Policy Optimization (PPO), one of the most popular reinforcement learning algorithms used today. We will cover the theoretical foundations that make PPO effective and stable, including its relationship with Trust Region Policy Optimization (TRPO). We'll also walk through practical implementation details and discuss common pitfalls.
        </p>
        <h2>Materials</h2>
        <ul>
            <li><a href="#">Presentation Slides (PDF)</a></li>
            <li><a href="#">Link to Paper</a></li>
            <li><a href="#">Colab Notebook with Code</a></li>
        </ul>
    </div>
</body>
</html>
